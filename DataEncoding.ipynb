{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a469d768-1399-4602-bc94-bae1d9d53933",
   "metadata": {},
   "source": [
    "# What is Data Encoding?\n",
    "It is the process of converting categorical data into numerical values so that ML algorithms can understand and process them.<br>\n",
    "Because ML models works with numbers not text.<br>\n",
    "Eg: models like regression, SVM, neural networks require numerical inputs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9475f8-b1f7-47e5-9237-eab998a3f581",
   "metadata": {},
   "source": [
    "# 1.Label Encoding\n",
    "Converts each category into a unique numeric value.<br>\n",
    "Eg: Red   → 0  \n",
    "    Blue  → 1  \n",
    "    Green → 2  \n",
    "\n",
    "**Advantages:<br>**\n",
    "i)Simple and memory-efficient.<br>\n",
    "ii)Good for ordinal data (like \"Low\", \"Medium\", \"High\").\n",
    "\n",
    "**Limitations: <br>**\n",
    "i)Label Encoding, by assigning unique integers (e.g., 0, 1, 2), creates an arbitrary order that is appropriate for ordinal data (like small < medium < large) but it's misleading for nominal data (like colors or cities).<br>\n",
    "\n",
    "**Example with Linear Regression or KNN:<br>**\n",
    "\n",
    "If \"Green\"=2 and \"Red\"=0, the algorithm might wrongly think Green is \"twice\" Red.<br>\n",
    "\n",
    "Distance-based models (KNN, SVM, clustering) may compute:<br><br>\n",
    "Distance(Red=0, Blue=1) = 1<br>\n",
    "Distance(Red=0, Green=2) = 2<br>\n",
    "→ implying Blue is more similar to Red than Green is, which is not logically true for colors.<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f55d78e-73b0-4111-95cb-7ae8dd5174ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "data = [\"Red\", \"Blue\", \"Green\", \"Blue\"]\n",
    "encoder = LabelEncoder() #creating object for LabelEncoder\n",
    "encoded_data=encoder.fit_transform(data)\n",
    "print(encoded_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1e8111-2abc-4f05-8c93-087dc622a3bf",
   "metadata": {},
   "source": [
    "**Why Red is assigned with 2,blue with 0 etc?**<br>\n",
    "A:  LabelEncoder() takes all unique values from your data.<br>\n",
    "    [\"Red\", \"Blue\", \"Green\", \"Blue\"]  <br>\n",
    "    Unique = {\"Red\", \"Blue\", \"Green\"}<br>\n",
    "    \n",
    "It sorts them alphabetically (lexicographically).<br>\n",
    "    Sorted = [\"Blue\", \"Green\", \"Red\"]<br>\n",
    "    Assigns 0, 1, 2 … based on this sorted list.<br>\n",
    "    \n",
    "So the rule is: LabelEncoder always assigns integers in alphabetical order of categories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d67be5e-6052-4e9e-8870-c822b69e6716",
   "metadata": {},
   "source": [
    "# 2.Ordinal Encoding\n",
    "\n",
    "Ordinal Encoding is a technique where categorical values are converted into integers based on some natural order or ranking that exists in the data.<br>\n",
    "Eg: We have education_level category then<br>\n",
    "    High School-->1<br>\n",
    "    College-->2<br>\n",
    "    Graduation-->3<br>\n",
    "    Post-graduation-->4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aa112296-0843-4f20-b47c-c9f3b7147615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0.]\n",
      " [2. 1.]\n",
      " [1. 2.]\n",
      " [2. 0.]\n",
      " [0. 2.]\n",
      " [1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "df=pd.DataFrame({\n",
    "    \"Size\":[\"Small\",\"Large\",\"Medium\",\"Large\",\"Small\",\"Medium\"],\n",
    "    \"Quality\": [\"Low\", \"Medium\", \"High\", \"Low\", \"High\",\"Medium\"]   #Every column has the same number of rows. Otherwise, it’s not a valid DataFrame,\n",
    "                                                                    #and operations like fit_transform() won't work.\n",
    "})\n",
    "#Define the order (You explicitly tell the encoder that the sizes follow this order)\n",
    "size_order = [\"Small\", \"Medium\", \"Large\"]\n",
    "quality_order = [\"Low\", \"Medium\", \"High\"]\n",
    "\n",
    "#create object for OrdinalEncoder\n",
    "encoder = OrdinalEncoder(categories=[size_order,quality_order]) #here categories are passed as list of lists bcz we might encode multiple columns at once\n",
    "                                                                #Even if you only encode one column, you must pass it as:\n",
    "encoded_data= encoder.fit_transform(df)\n",
    "print(encoded_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2511181-d47d-48e9-95ed-1ba25c96bb4f",
   "metadata": {},
   "source": [
    "**Advantages**<br>\n",
    "i)Memory Efficient : It uses a single integer per category, unlike one-hot encoding which creates multiple columns.<br>\n",
    "ii)Works Well with Some ML Algorithms : Tree-based models (like Decision Trees, Random Forests, XGBoost) can handle ordinal encoded data well because they split based on thresholds.<br>\n",
    "iii)Preserves information about relative ordering<br>\n",
    "\n",
    "**Limitations**<br>\n",
    "i)Not suitable for nomial data<br>\n",
    "ii)Requires Domain Knowledge : You must explicitly define the order for categories based on context.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ff0991-65fd-4410-bc71-13887f153d72",
   "metadata": {},
   "source": [
    "# 3.One-hot Encoding or Nominal Endcoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163d57b0-6a99-4151-85dd-9fb1b193b9c6",
   "metadata": {},
   "source": [
    "It is a technique to convert categorical data into numerical data in which each category is represented as a binary vector.<br>\n",
    "It creates new columns for each category where 1 means the category is present and 0 means it is not.<br>\n",
    "\n",
    "It is mostly used for nominal categorical data where no order exists.\n",
    "\n",
    "For example: You have a color column [\"Red\", \"Blue\", \"Green\"] <br>\n",
    "                we represent one-hot coding as:<br>\n",
    "                Red-->[0,0,1]<br>\n",
    "                Blue-->[1,0,0]<br>\n",
    "                Green-->[0,1,0]<br>\n",
    "\n",
    "Why is \"Red\" encoded as [0, 0, 1] and not something else like [0, 1, 0]? What decides this?<br>\n",
    "A: How One-Hot Encoding Assigns Vectors:<br>\n",
    "     **1.List all unique categories from the column<br>**\n",
    "     eg: [\"Red\", \"Blue\", \"Green\"]<br><br>\n",
    "**2.Sort or Order Them<br>**\n",
    "     Depending on the encoder, it might sort them alphabetically or keep the order of appearance.<br>\n",
    "     [\"Blue\", \"Green\", \"Red\"]<br><br>\n",
    "**3.Assign Columns Based on Order<br>**\n",
    "Each unique category is assigned one column in this order.<br>\n",
    "        Column 0 → Blue  <br>\n",
    "        Column 1 → Green  <br>\n",
    "        Column 2 → Red<br><br>\n",
    "**4.Create Binary Vectors<br>**\n",
    "For each row, the encoder places 1 in the column corresponding to that category, and 0 elsewhere.\n",
    "\n",
    "| Category | Blue | Green | Red |\n",
    "| -------- | ---- | ----- | --- |\n",
    "| Blue     | 1    | 0     | 0   |\n",
    "| Green    | 0    | 1     | 0   |\n",
    "| Red      | 0    | 0     | 1   |\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dead7eab-968d-4e17-b12c-4af1c841e809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
      "\twith 6 stored elements and shape (6, 3)>\n",
      "  Coords\tValues\n",
      "  (0, 2)\t1.0\n",
      "  (1, 1)\t1.0\n",
      "  (2, 2)\t1.0\n",
      "  (3, 0)\t1.0\n",
      "  (4, 0)\t1.0\n",
      "  (5, 1)\t1.0 \n",
      "\n",
      "[[0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data=pd.DataFrame({\n",
    "    \"Color\":[\"Red\",\"Green\",\"Red\",\"Blue\",\"Blue\",\"Green\"]\n",
    "})\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = OneHotEncoder()\n",
    "encoded_data=encoder.fit_transform(data)\n",
    "print(encoded_data,\"\\n\")\n",
    "print(encoded_data.toarray())   # we converted encoded_data to  array because the result we get is in sparse matrix form \n",
    "                                # A sparse matrix only stores the positions where there's a 1\n",
    "                                # sparse matrix is memory efficient : Imagine you have 1 million rows and 1000 categories.\n",
    "                                # A dense matrix would store 1 million × 1000 = 1 billion elements, most of which are zeros → memory-heavy!\n",
    "                                # where sparse only store pos of 1s...But for our understanding we converted to dense array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "769b8c4c-19a2-45be-8c01-cc8f51a01a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Color_Blue  Color_Green  Color_Red\n",
      "0       False        False       True\n",
      "1       False         True      False\n",
      "2       False        False       True\n",
      "3        True        False      False\n",
      "4        True        False      False\n",
      "5       False         True      False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(pd.get_dummies(data))#is a Pandas function used to convert categorical variables into dummy/indicator variables, which is essentially one-hot encoding.\n",
    "pd.get_dummies(data).shape #to know how many new rows and columns are created"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6fcd24-8b47-4d1e-8d8f-2ae7cd4caf21",
   "metadata": {},
   "source": [
    "**Advantages of One-Hot Encoding**<br>\n",
    "i)Widely used for nominal data<br>\n",
    "ii)Better for algorithms sensitive to distance<br><br>\n",
    "**Limitations**<br>\n",
    "**i)Increased Dimensionality<br>**\n",
    "    One-hot encoding creates one new column per category.<br>\n",
    "    For features with many unique categories (high cardinality), this leads to a huge number of columns.<br>\n",
    "    Example: A \"Country\" column with 200 countries will create 200 new columns → huge memory and computational cost!<br><br>\n",
    "**ii)Sparsity<br>**\n",
    "Since each row only has one 1 and all others are 0, the resulting matrix is mostly zeros.<br>\n",
    "This sparsity makes the data inefficient to store and process in some cases.<br>\n",
    "**iii)Overfitting**<br>\n",
    "When there are many categories, this results in a large number of features, but most of them are zeros.<br>\n",
    "so the model memorizes specific patterns instead of learning general trends.Hence it leads to  poor performace for unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15bb61c-6aaa-47ad-8345-2f3a4e109c4d",
   "metadata": {},
   "source": [
    "# 4.Target Guided Ordinal Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e2436b-7c5e-441b-b353-8df29335c5bf",
   "metadata": {},
   "source": [
    "It is a technique used to encode categorial data based on relationship with the target data.<br>\n",
    "This technique is useful when we have a categorical column with more unique categories.<br>\n",
    "\n",
    "In this we replace every category in categorical variable with a numerical value based on mean or median of target variable of that category.<br>\n",
    "Captures relationship with the target : It means that the encoding assigns higher values to categories that are more likely to have a positive outcome (or whatever the target represents)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ec58f3f5-8e62-457d-99a0-c2eb51eed14c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City\n",
      "Bangalore    125.000000\n",
      "Delhi         86.666667\n",
      "Mumbai       100.000000\n",
      "Name: Price, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Encoding City Based on House Prices\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({\n",
    "    \"City\": [\"Mumbai\", \"Delhi\", \"Bangalore\", \"Delhi\", \"Mumbai\", \"Bangalore\", \"Mumbai\", \"Delhi\"],\n",
    "    \"Price\": [100, 80, 120, 85, 110, 130, 90, 95]\n",
    "})\n",
    "\n",
    "grouping=df.groupby(\"City\") #Grouping data based on City\n",
    "\n",
    "mean_prices=grouping[\"Price\"].mean() #In each group calculating mean of Price\n",
    "print(mean_prices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "cc07ad75-9f79-4527-bff3-d538fdd9f35a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        City  Price  City_encoded\n",
      "0     Mumbai    100    100.000000\n",
      "1      Delhi     80     86.666667\n",
      "2  Bangalore    120    125.000000\n",
      "3      Delhi     85     86.666667\n",
      "4     Mumbai    110    100.000000\n",
      "5  Bangalore    130    125.000000\n",
      "6     Mumbai     90    100.000000\n",
      "7      Delhi     95     86.666667\n"
     ]
    }
   ],
   "source": [
    "df[\"City_encoded\"] = df[\"City\"].map(mean_prices)  # Corresponding mean price is mapped to its City\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437eafd9-11a7-4c11-bd06-00af130b53e0",
   "metadata": {},
   "source": [
    "**Advantages**<br>\n",
    "i)Works well for high-cardinality features :  Instead of creating many columns (like in one-hot encoding), it keeps things simple.<br>\n",
    "ii)Captures relationship with the target <br>\n",
    "iii)Improves model performance in supervised learning :Makes it easier for the model to learn patterns related to the target.<br><br>\n",
    "**Limitations**<br>\n",
    "i)Only works in supervised problems : It relies on the target variable, so you can’t use it in unsupervised learning.><br>\n",
    "ii)Sensitive Outliers: If a city only has one very expensive house, its average price will be high → the model thinks all houses there are expensive.<br>\n",
    "\n",
    "For example:<br>\n",
    "\n",
    "| City     | Price|\n",
    "| -------- | ---- |\n",
    "| Mumbai   | 100  |\n",
    "| Delhi    | 80   |\n",
    "| Banglore | 120  |\n",
    "| Smalltown|1000  |\n",
    "| Mumbai   | 110  |\n",
    "| Delhi    | 85   |\n",
    "| Banglore | 130  |\n",
    "\n",
    "\n",
    "Mean of prices after grouping: <br>\n",
    "Bangalore --> 125.0 <br>\n",
    "Delhi      --> 82.5 <br>\n",
    "Mumbai      -->105.0<br>\n",
    "SmallTown   -->1000.0<br>\n",
    "\n",
    "\n",
    "SmallTown only has 1 house, but the model thinks all SmallTown houses are extremely expensive.<br>\n",
    "When a new SmallTown house comes, the model predicts ~1000 → may be wrong if it’s cheaper.<br>\n",
    "\n",
    "So the problem is: <br>\n",
    "SmallTown's encoded value = 1000 → much larger than others\n",
    "Even though it’s only one data point, the model might treat it as extremely expensive and learn misleading patterns!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ace716-e555-48d4-98a4-8e57098475ba",
   "metadata": {},
   "source": [
    "# 5.Frequency Encoding\n",
    "Frequency Encoding replaces each category in a column with the proportion or count of how often that category occurs in the dataset.<br>\n",
    "For Example: Purchase Prediction <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0eabfc97-39f6-487a-ba83-b340c358168c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Brand  Purchased\n",
      "0     Apple          1\n",
      "1   Samsung          1\n",
      "2   OnePlus          0\n",
      "3   Samsung          1\n",
      "4     Apple          1\n",
      "5    Xiaomi          0\n",
      "6   OnePlus          0\n",
      "7     Apple          1\n",
      "8    Realme          0\n",
      "9    Xiaomi          0\n",
      "10  Samsung          1\n",
      "11   Realme          0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"Brand\": [\"Apple\", \"Samsung\", \"OnePlus\", \"Samsung\", \"Apple\", \"Xiaomi\", \"OnePlus\", \"Apple\", \"Realme\", \"Xiaomi\", \"Samsung\", \"Realme\"],\n",
    "    \"Purchased\": [1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0]  # 1 = purchased, 0 = not purchased\n",
    "})\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f744bbc4-7a50-4103-8ff1-574855722a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brand\n",
      "Apple      3\n",
      "Samsung    3\n",
      "OnePlus    2\n",
      "Xiaomi     2\n",
      "Realme     2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count how many times each brand appears\n",
    "brand_count = df['Brand'].value_counts()\n",
    "print(brand_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "49db21e0-6914-4f10-9605-a2666bb4d726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Brand  Purchased  Brand_encoded_count\n",
      "0     Apple          1                    3\n",
      "1   Samsung          1                    3\n",
      "2   OnePlus          0                    2\n",
      "3   Samsung          1                    3\n",
      "4     Apple          1                    3\n",
      "5    Xiaomi          0                    2\n",
      "6   OnePlus          0                    2\n",
      "7     Apple          1                    3\n",
      "8    Realme          0                    2\n",
      "9    Xiaomi          0                    2\n",
      "10  Samsung          1                    3\n",
      "11   Realme          0                    2\n"
     ]
    }
   ],
   "source": [
    "# Map counts to the 'Brand' column\n",
    "df['Brand_encoded_count'] = df['Brand'].map(brand_count)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9b38e4da-818d-4f70-97af-fcf8c39ffcb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brand\n",
      "Apple      0.250000\n",
      "Samsung    0.250000\n",
      "OnePlus    0.166667\n",
      "Xiaomi     0.166667\n",
      "Realme     0.166667\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "brand_freq = df['Brand'].value_counts(normalize=True) #normalize=True gives proportion values like Apple-->3/12=0.25\n",
    "print(brand_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac56020-50a5-4d4d-a111-5b9f1e39d284",
   "metadata": {},
   "source": [
    "**Why Frequency Encoding Helps Here**\n",
    "\n",
    "✔ Popular brands like Apple and Samsung → higher frequency → more likely to be purchased<br>\n",
    "✔ Less popular brands → lower frequency → less likely to be purchased<br>\n",
    "✔ The model can now interpret brand popularity as a numeric feature<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a1039a-44b6-4e11-876e-a74a15634a6a",
   "metadata": {},
   "source": [
    "**Advantages**<br>\n",
    "i)Simple to implement bcz it doesn’t create many extra columns like one-hot encoding does.<br>\n",
    "ii)Automatically identifies \"popular\" vs \"rare\" categories - Models can learn that popular = important<br>\n",
    "iii)Can be useful for high cardinality data like having many unique categories.<br>\n",
    "\n",
    "**Limitations**<br>\n",
    "i)Doesn’t capture relationships between categories : “Apple” and “Samsung” might be treated equally just because they both appear 25% of the time, even if they have very different customer behaviors.<br>\n",
    "ii)Can be misleading with rare categories : A luxury brand bought only once might be treated as irrelevant because its frequency is 1/1000 = 0.001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b82dc52-fda3-49a0-9577-d48d018ec008",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
